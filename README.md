# üö≤ Big Data Pipeline : Analyse TBM & Architecture Distribu√©e

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Hadoop](https://img.shields.io/badge/Hadoop-3.3-blue.svg)](https://hadoop.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5-orange.svg)](https://spark.apache.org/)
[![Docker](https://img.shields.io/badge/Docker-Enabled-2496ED.svg)](https://www.docker.com/)

Ce projet impl√©mente un pipeline de donn√©es complet (ETL) pour l'analyse des v√©los en libre-service de Bordeaux (TBM). Il a √©t√© con√ßu dans un cadre √©ducatif pour d√©montrer la mise en place d'un cluster Hadoop distribu√©, l'orchestration de flux de donn√©es et le traitement analytique interactif.

## üèóÔ∏è Architecture du Projet

L'infrastructure simule un environnement de production distribu√© gr√¢ce √† la conteneurisation Docker.

1.  [cite_start]**Cluster Hadoop** : Configuration multi-n≈ìuds (1 Master + 2 Workers) assurant le stockage (HDFS) et la gestion des ressources (YARN)[cite: 3, 5].
2.  **Orchestration (Airflow)** : Automatisation des scripts d'ingestion pour collecter les donn√©es API en temps r√©el.
3.  **Traitement (Spark Shell)** : Analyse exploratoire et calculs distribu√©s sur les donn√©es brutes stock√©es dans HDFS.

## ‚öôÔ∏è Pr√©requis

- **Docker Desktop** (avec support Linux activ√©).
- **Python 3.x** & **Apache Airflow**.
- [cite_start]Image Docker de base : `liliasfaxi/hadoop-cluster:latest`[cite: 8].

## üöÄ Installation et D√©ploiement

### 1. Initialisation du R√©seau

[cite_start]Cr√©ation d'un r√©seau pont (bridge) pour permettre la communication isol√©e entre les conteneurs du cluster[cite: 14].

```bash
docker network create --driver bridge hadoop
2. D√©marrage des Conteneurs
Le d√©ploiement se fait en trois parties : le n≈ìud ma√Ætre (Master) et les deux n≈ìuds esclaves (Workers).

N≈ìud Ma√Ætre (NameNode & ResourceManager) :

Bash

docker run -itd --net hadoop -p 9870:9870 -p 8088:8088 -p 7077:7077 -p 16010:16010 --name hadoop-master --hostname hadoop-master liliasfaxi/hadoop-cluster:latest

[Mapping des ports pour l'acc√®s aux UIs Web depuis la machine h√¥te].

N≈ìuds Esclaves (DataNodes) :

Bash

docker run -itd -p 8040:8042 --net hadoop --name hadoop-worker1 --hostname hadoop-worker1 liliasfaxi/hadoop-cluster:latest
docker run -itd -p 8041:8042 --net hadoop --name hadoop-worker2 --hostname hadoop-worker2 liliasfaxi/hadoop-cluster:latest
.

3. Lancement des Services Hadoop
Une fois les conteneurs instanci√©s, il faut d√©marrer les d√©mons HDFS et YARN.

Bash

# Acc√®s au shell du conteneur ma√Ætre
docker exec -it hadoop-master bash

# Script d'initialisation fourni
./start-hadoop.sh
.
+1

Interfaces de Monitoring : * HDFS NameNode : http://localhost:9870 * YARN ResourceManager : http://localhost:8088
+1

üîÑ Workflow d'Utilisation
√âtape 1 : Ingestion Automatis√©e (Airflow)
Un DAG Airflow est configur√© pour ex√©cuter p√©riodiquement le script de collecte. Ce script r√©cup√®re les donn√©es JSON de l'API TBM et les d√©pose dans HDFS.

Action √©quivalente en ligne de commande HDFS :

Bash

# Cr√©ation du r√©pertoire cible
hdfs dfs -mkdir -p input

# Injection du fichier (effectu√© par le script Python)
hdfs dfs -put purchases.txt input/
.
+1

√âtape 2 : Analyse Interactive (Spark Shell)
Le traitement des donn√©es se fait via le shell Spark (Scala), permettant des op√©rations rapides en m√©moire.

Lancement de Spark : Depuis le conteneur hadoop-master :

Bash

spark-shell
.

Exemple de traitement :

Scala

// Chargement du fichier depuis HDFS dans un RDD
val data = sc.textFile("input/data_tbm.json")

// Comptage des entr√©es
data.count()

// Affichage des premi√®res lignes
data.take(5).foreach(println)
.

üë• Auteurs et Contributeurs
Axel GODART - Developer & DATA

Encadrement : Projet r√©alis√© dans le cadre du cours "Traitement Batch avec Hadoop HDFS".

üìÑ Licence
Ce projet est sous licence MIT. Consultez le fichier LICENSE pour plus de d√©tails.

Plaintext

MIT License

Copyright (c) 2024 [Votre Nom]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
