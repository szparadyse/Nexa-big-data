# üö≤ Big Data Pipeline : Analyse TBM & Architecture Distribu√©e

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Hadoop](https://img.shields.io/badge/Hadoop-3.3-blue.svg)](https://hadoop.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5-orange.svg)](https://spark.apache.org/)
[![Docker](https://img.shields.io/badge/Docker-Enabled-2496ED.svg)](https://www.docker.com/)

Ce projet impl√©mente un pipeline de donn√©es complet (ETL) pour l'analyse des v√©los en libre-service de Bordeaux (TBM). Il a √©t√© con√ßu dans un cadre √©ducatif pour d√©montrer la mise en place d'un cluster Hadoop distribu√©, l'orchestration de flux de donn√©es et le traitement analytique interactif.

üèóÔ∏è Architecture du Projet
L'infrastructure simule un environnement de production distribu√© gr√¢ce √† la conteneurisation Docker :

Cluster Hadoop : Configuration multi-n≈ìuds (1 Master + 2 Workers) assurant le stockage (HDFS) et la gestion des ressources (YARN).

Orchestration (Airflow) : Automatisation des scripts d'ingestion pour collecter les donn√©es API en temps r√©el.

Traitement (Spark Shell) : Analyse exploratoire et calculs distribu√©s sur les donn√©es brutes stock√©es dans HDFS.

‚öôÔ∏è Pr√©requis
Docker Desktop (avec support Linux activ√©).

Python 3.x & Apache Airflow.

Image Docker de base : liliasfaxi/hadoop-cluster:latest

üöÄ Installation et D√©ploiement

1. Initialisation du R√©seau
   Cr√©ation d'un r√©seau pont (bridge) pour permettre la communication isol√©e entre les conteneurs du cluster.

Bash

docker network create --driver bridge hadoop 2. D√©marrage des Conteneurs
Le d√©ploiement se fait en trois parties : le n≈ìud ma√Ætre (Master) et les deux n≈ìuds esclaves (Workers).

N≈ìud Ma√Ætre (NameNode & ResourceManager) :

Bash

docker run -itd \
 --net hadoop \
 -p 9870:9870 -p 8088:8088 -p 7077:7077 -p 16010:16010 \
 --name hadoop-master \
 --hostname hadoop-master \
 liliasfaxi/hadoop-cluster:latest
N≈ìuds Esclaves (DataNodes) :

Bash

docker run -itd -p 8040:8042 --net hadoop --name hadoop-worker1 --hostname hadoop-worker1 liliasfaxi/hadoop-cluster:latest
docker run -itd -p 8041:8042 --net hadoop --name hadoop-worker2 --hostname hadoop-worker2 liliasfaxi/hadoop-cluster:latest 3. Lancement des Services Hadoop
Une fois les conteneurs instanci√©s, il faut d√©marrer les d√©mons HDFS et YARN.

Bash

# Acc√®s au shell du conteneur ma√Ætre

docker exec -it hadoop-master bash

# Lancement du script d'initialisation √† l'int√©rieur du conteneur

./start-hadoop.sh
üìä Interfaces de Monitoring
HDFS NameNode : http://localhost:9870

YARN ResourceManager : http://localhost:8088

üîÑ Workflow d'Utilisation
√âtape 1 : Ingestion Automatis√©e (Airflow)
Un DAG Airflow ex√©cute p√©riodiquement un script de collecte qui r√©cup√®re les donn√©es JSON de l'API TBM et les d√©pose dans HDFS.

Action √©quivalente en ligne de commande :

Bash

# Cr√©ation du r√©pertoire cible dans HDFS

hdfs dfs -mkdir -p /user/input

# Injection manuelle d'un fichier

hdfs dfs -put data_tbm.json /user/input/
√âtape 2 : Analyse Interactive (Spark Shell)
Le traitement se fait via le shell Spark (Scala) pour des calculs rapides en m√©moire.

Lancement de Spark :

Bash

spark-shell
Exemple de traitement Scala :

Scala

// Chargement du fichier depuis HDFS
val data = sc.textFile("/user/input/data_tbm.json")

// Comptage des entr√©es
println(s"Nombre total d'entr√©es : ${data.count()}")

// Affichage des 5 premi√®res lignes
data.take(5).foreach(println)
üë• Auteurs et Contributeurs
Axel GODART - Developer & DATA

Projet r√©alis√© dans le cadre du cours "Traitement Batch avec Hadoop HDFS".

üìÑ Licence
Ce projet est sous licence MIT.

Plaintext

Copyright (c) 2024 Axel GODART

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions...
