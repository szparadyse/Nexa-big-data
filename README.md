# üö≤ Big Data Pipeline : Analyse TBM & Architecture Distribu√©e

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Hadoop](https://img.shields.io/badge/Hadoop-3.3-blue.svg)](https://hadoop.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5-orange.svg)](https://spark.apache.org/)
[![Docker](https://img.shields.io/badge/Docker-Enabled-2496ED.svg)](https://www.docker.com/)

Ce projet impl√©mente un **pipeline Big Data complet (ETL)** pour l'analyse des donn√©es de v√©los en libre-service de Bordeaux (TBM).  
Il a √©t√© con√ßu dans un cadre √©ducatif afin de d√©montrer :

- la mise en place d'un **cluster Hadoop distribu√©**
- l'orchestration des flux de donn√©es
- le traitement analytique interactif avec Spark

---

## üèóÔ∏è Architecture du Projet

L'infrastructure simule un environnement de production distribu√© gr√¢ce √† la conteneurisation Docker.

- **Cluster Hadoop** : Configuration multi-n≈ìuds (1 Master + 2 Workers) assurant le stockage via **HDFS** et la gestion des ressources avec **YARN**
- **Orchestration (Apache Airflow)** : Automatisation de l'ingestion des donn√©es via un DAG r√©cup√©rant les donn√©es depuis l'API TBM
- **Traitement (Spark Shell)** : Analyse exploratoire et calculs distribu√©s sur les donn√©es stock√©es dans HDFS

---

## ‚öôÔ∏è Pr√©requis

- **Docker Desktop** (avec support Linux activ√©)
- **Python 3.x**
- **Apache Airflow**
- Image Docker Hadoop : `liliasfaxi/hadoop-cluster:latest`

---

## üöÄ Installation et D√©ploiement

### 1. Cr√©ation du r√©seau Docker

Cr√©ation d'un r√©seau bridge pour permettre la communication isol√©e entre les conteneurs Hadoop.

```bash
docker network create --driver bridge hadoop
```

### 2. D√©marrage des conteneurs Hadoop

Le cluster est compos√© de **trois conteneurs** :
- 1 n≈ìud ma√Ætre (NameNode & ResourceManager)
- 2 n≈ìuds workers (DataNodes)

#### üß† N≈ìud ma√Ætre (NameNode & ResourceManager)

```bash
docker run -itd \
  --net hadoop \
  -p 9870:9870 \
  -p 8088:8088 \
  -p 7077:7077 \
  -p 16010:16010 \
  --name hadoop-master \
  --hostname hadoop-master \
  liliasfaxi/hadoop-cluster:latest
```

Ces ports permettent l'acc√®s aux interfaces Web Hadoop depuis la machine h√¥te.

#### üóÑÔ∏è N≈ìuds workers (DataNodes)

**Worker 1**

```bash
docker run -itd \
  --net hadoop \
  -p 8040:8042 \
  --name hadoop-worker1 \
  --hostname hadoop-worker1 \
  liliasfaxi/hadoop-cluster:latest
```

**Worker 2**

```bash
docker run -itd \
  --net hadoop \
  -p 8041:8042 \
  --name hadoop-worker2 \
  --hostname hadoop-worker2 \
  liliasfaxi/hadoop-cluster:latest
```

### 3. Lancement des services Hadoop

**Connexion au conteneur ma√Ætre**

```bash
docker exec -it hadoop-master bash
```

**D√©marrage de HDFS et YARN**

```bash
./start-hadoop.sh
```

#### üìä Interfaces de monitoring

- **HDFS NameNode** : [http://localhost:9870](http://localhost:9870)
- **YARN ResourceManager** : [http://localhost:8088](http://localhost:8088)

---

## üîÑ Workflow d'Utilisation

### √âtape 1 : Ingestion automatis√©e (Apache Airflow)

Un DAG Apache Airflow ex√©cute p√©riodiquement un script Python qui :
- r√©cup√®re les donn√©es JSON depuis l'API TBM
- stocke les fichiers dans HDFS

**√âquivalent en ligne de commande HDFS**

```bash
# Cr√©ation du r√©pertoire cible
hdfs dfs -mkdir -p input

# Injection du fichier dans HDFS
hdfs dfs -put purchases.txt input/
```

### √âtape 2 : Analyse interactive (Spark Shell)

Les analyses sont r√©alis√©es via Spark Shell (Scala) pour un traitement rapide en m√©moire.

**Lancement de Spark (depuis hadoop-master)**

```bash
spark-shell
```

**Exemple de traitement Spark**

```scala
// Chargement des donn√©es depuis HDFS
val data = sc.textFile("input/data_tbm.json")

// Comptage du nombre d'entr√©es
data.count()

// Affichage des premi√®res lignes
data.take(5).foreach(println)
```

---

## üë• Auteurs et Contributeurs

**Axel GODART** ‚Äî Developer & Data

**Encadrement** :  
Projet r√©alis√© dans le cadre du cours ¬´ Traitement Batch avec Hadoop HDFS ¬ª.

---

## üìÑ Licence

Ce projet est sous licence MIT.  
Consultez le fichier [LICENSE](LICENSE) pour plus de d√©tails.

```
MIT License

Copyright (c) 2024 Axel GODART

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```