# ğŸš² Big Data Pipeline : Analyse TBM & Architecture DistribuÃ©e

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Hadoop](https://img.shields.io/badge/Hadoop-3.3-blue.svg)](https://hadoop.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5-orange.svg)](https://spark.apache.org/)
[![Docker](https://img.shields.io/badge/Docker-Enabled-2496ED.svg)](https://www.docker.com/)

Ce projet implÃ©mente un **pipeline Big Data complet (ETL)** pour lâ€™analyse des donnÃ©es de vÃ©los en libre-service de Bordeaux (TBM).  
Il a Ã©tÃ© conÃ§u dans un cadre Ã©ducatif afin de dÃ©montrer :

- la mise en place dâ€™un **cluster Hadoop distribuÃ©**,
- lâ€™orchestration des flux de donnÃ©es,
- le traitement analytique interactif avec Spark.

---

## ğŸ—ï¸ Architecture du Projet

Lâ€™infrastructure simule un environnement de production distribuÃ© grÃ¢ce Ã  la conteneurisation Docker.

- **Cluster Hadoop** :  
  Configuration multi-nÅ“uds (1 Master + 2 Workers) assurant le stockage via **HDFS** et la gestion des ressources avec **YARN**.

- **Orchestration (Apache Airflow)** :  
  Automatisation de lâ€™ingestion des donnÃ©es via un DAG rÃ©cupÃ©rant les donnÃ©es depuis lâ€™API TBM.

- **Traitement (Spark Shell)** :  
  Analyse exploratoire et calculs distribuÃ©s sur les donnÃ©es stockÃ©es dans HDFS.

---

## âš™ï¸ PrÃ©requis

- **Docker Desktop** (avec support Linux activÃ©)
- **Python 3.x**
- **Apache Airflow**
- Image Docker Hadoop :  
  `liliasfaxi/hadoop-cluster:latest`

---

## ğŸš€ Installation et DÃ©ploiement

### 1. CrÃ©ation du rÃ©seau Docker

CrÃ©ation dâ€™un rÃ©seau bridge pour permettre la communication isolÃ©e entre les conteneurs Hadoop.

```bash
docker network create --driver bridge hadoop
```

2. DÃ©marrage des conteneurs Hadoop
   Le cluster est composÃ© dâ€™un nÅ“ud maÃ®tre et de deux nÅ“uds workers.

NÅ“ud maÃ®tre (NameNode & ResourceManager)
bash
Copier le code
docker run -itd \
 --net hadoop \
 -p 9870:9870 \
 -p 8088:8088 \
 -p 7077:7077 \
 -p 16010:16010 \
 --name hadoop-master \
 --hostname hadoop-master \
 liliasfaxi/hadoop-cluster:latest
Ces ports permettent lâ€™accÃ¨s aux interfaces Web Hadoop depuis la machine hÃ´te.

NÅ“uds workers (DataNodes)
bash
Copier le code
docker run -itd \
 --net hadoop \
 -p 8040:8042 \
 --name hadoop-worker1 \
 --hostname hadoop-worker1 \
 liliasfaxi/hadoop-cluster:latest
bash
Copier le code
docker run -itd \
 --net hadoop \
 -p 8041:8042 \
 --name hadoop-worker2 \
 --hostname hadoop-worker2 \
 liliasfaxi/hadoop-cluster:latest 3. Lancement des services Hadoop
Connexion au conteneur maÃ®tre :

bash
Copier le code
docker exec -it hadoop-master bash
DÃ©marrage de HDFS et YARN :

bash
Copier le code
./start-hadoop.sh
Interfaces de monitoring
HDFS NameNode : http://localhost:9870

YARN ResourceManager : http://localhost:8088

ğŸ”„ Workflow dâ€™Utilisation
Ã‰tape 1 : Ingestion automatisÃ©e (Airflow)
Un DAG Apache Airflow exÃ©cute pÃ©riodiquement un script Python qui :

rÃ©cupÃ¨re les donnÃ©es JSON depuis lâ€™API TBM,

stocke les fichiers dans HDFS.

Ã‰quivalent en ligne de commande HDFS :

bash
Copier le code

# CrÃ©ation du rÃ©pertoire cible

hdfs dfs -mkdir -p input

# Injection du fichier dans HDFS

hdfs dfs -put purchases.txt input/
Ã‰tape 2 : Analyse interactive (Spark Shell)
Les analyses sont rÃ©alisÃ©es via Spark Shell (Scala) pour un traitement rapide en mÃ©moire.

Lancement de Spark depuis le conteneur hadoop-master :

bash
Copier le code
spark-shell
Exemple de traitement :

scala
Copier le code
// Chargement des donnÃ©es depuis HDFS
val data = sc.textFile("input/data_tbm.json")

// Comptage du nombre dâ€™entrÃ©es
data.count()

// Affichage des premiÃ¨res lignes
data.take(5).foreach(println)
ğŸ‘¥ Auteurs et Contributeurs
Axel GODART â€” Developer & Data

Encadrement :
Projet rÃ©alisÃ© dans le cadre du cours Â« Traitement Batch avec Hadoop HDFS Â».

ğŸ“„ Licence
Ce projet est sous licence MIT.
Consultez le fichier LICENSE pour plus de dÃ©tails.

vbnet
Copier le code
MIT License

Copyright (c) 2024 Axel GODART

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT W## 2. ğŸš€ DÃ©marrage des conteneurs Hadoop

Le cluster est composÃ© de **trois conteneurs** :

- 1 nÅ“ud maÃ®tre (NameNode & ResourceManager)
- 2 nÅ“uds workers (DataNodes)

---

### ğŸ§  NÅ“ud maÃ®tre (NameNode & ResourceManager)

```bash
docker run -itd \
  --net hadoop \
  -p 9870:9870 \
  -p 8088:8088 \
  -p 7077:7077 \
  -p 16010:16010 \
  --name hadoop-master \
  --hostname hadoop-master \
  liliasfaxi/hadoop-cluster:latest
Ces ports permettent lâ€™accÃ¨s aux interfaces Web Hadoop depuis la machine hÃ´te.

ğŸ—„ï¸ NÅ“uds workers (DataNodes)
Worker 1

bash
Copier le code
docker run -itd \
  --net hadoop \
  -p 8040:8042 \
  --name hadoop-worker1 \
  --hostname hadoop-worker1 \
  liliasfaxi/hadoop-cluster:latest
Worker 2

bash
Copier le code
docker run -itd \
  --net hadoop \
  -p 8041:8042 \
  --name hadoop-worker2 \
  --hostname hadoop-worker2 \
  liliasfaxi/hadoop-cluster:latest
3. âš™ï¸ Lancement des services Hadoop
Connexion au conteneur maÃ®tre
bash
Copier le code
docker exec -it hadoop-master bash
DÃ©marrage de HDFS et YARN
bash
Copier le code
./start-hadoop.sh
ğŸ“Š Interfaces de monitoring
HDFS NameNode : http://localhost:9870

YARN ResourceManager : http://localhost:8088

ğŸ”„ Workflow dâ€™utilisation
Ã‰tape 1 : Ingestion automatisÃ©e (Apache Airflow)
Un DAG Apache Airflow exÃ©cute pÃ©riodiquement un script Python qui :

rÃ©cupÃ¨re les donnÃ©es JSON depuis lâ€™API TBM,

stocke les fichiers dans HDFS.

Ã‰quivalent en ligne de commande HDFS
bash
Copier le code
# CrÃ©ation du rÃ©pertoire cible
hdfs dfs -mkdir -p input

# Injection du fichier dans HDFS
hdfs dfs -put purchases.txt input/
Ã‰tape 2 : Analyse interactive (Spark Shell)
Les analyses sont rÃ©alisÃ©es via Spark Shell (Scala) pour un traitement rapide en mÃ©moire.

Lancement de Spark (depuis hadoop-master)
bash
Copier le code
spark-shell
Exemple de traitement Spark
scala
Copier le code
// Chargement des donnÃ©es depuis HDFS
val data = sc.textFile("input/data_tbm.json")

// Comptage du nombre dâ€™entrÃ©es
data.count()

// Affichage des premiÃ¨res lignes
data.take(5).foreach(println)
ğŸ‘¥ Auteurs et Contributeurs
Axel GODART â€” Developer & Data

Encadrement :
Projet rÃ©alisÃ© dans le cadre du cours
Â« Traitement Batch avec Hadoop HDFS Â».

ğŸ“„ Licence
Ce projet est sous licence MIT.
Consultez le fichier LICENSE pour plus de dÃ©tails.

pgsql
Copier le code
MIT License

Copyright (c) 2024 Axel GODART

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software.ARRANTY OF ANY KIND.
```
