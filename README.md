# üö≤ Big Data Pipeline : Analyse TBM & Architecture Distribu√©e

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Hadoop](https://img.shields.io/badge/Hadoop-3.3-blue.svg)](https://hadoop.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5-orange.svg)](https://spark.apache.org/)
[![Docker](https://img.shields.io/badge/Docker-Enabled-2496ED.svg)](https://www.docker.com/)

Ce projet impl√©mente un **pipeline Big Data complet (ETL)** pour l‚Äôanalyse des donn√©es de v√©los en libre-service de Bordeaux (TBM).  
Il a √©t√© con√ßu dans un cadre √©ducatif afin de d√©montrer :

- la mise en place d‚Äôun **cluster Hadoop distribu√©**,
- l‚Äôorchestration des flux de donn√©es,
- le traitement analytique interactif avec Spark.

---

## üèóÔ∏è Architecture du Projet

L‚Äôinfrastructure simule un environnement de production distribu√© gr√¢ce √† la conteneurisation Docker.

- **Cluster Hadoop** :  
  Configuration multi-n≈ìuds (1 Master + 2 Workers) assurant le stockage via **HDFS** et la gestion des ressources avec **YARN**.

- **Orchestration (Apache Airflow)** :  
  Automatisation de l‚Äôingestion des donn√©es via un DAG r√©cup√©rant les donn√©es depuis l‚ÄôAPI TBM.

- **Traitement (Spark Shell)** :  
  Analyse exploratoire et calculs distribu√©s sur les donn√©es stock√©es dans HDFS.

---

## ‚öôÔ∏è Pr√©requis

- **Docker Desktop** (avec support Linux activ√©)
- **Python 3.x**
- **Apache Airflow**
- Image Docker Hadoop :  
  `liliasfaxi/hadoop-cluster:latest`

---

## üöÄ Installation et D√©ploiement

### 1. Cr√©ation du r√©seau Docker

Cr√©ation d‚Äôun r√©seau bridge pour permettre la communication isol√©e entre les conteneurs Hadoop.

```bash
docker network create --driver bridge hadoop
2. D√©marrage des conteneurs Hadoop
Le cluster est compos√© d‚Äôun n≈ìud ma√Ætre et de deux n≈ìuds workers.

N≈ìud ma√Ætre (NameNode & ResourceManager)
bash
Copier le code
docker run -itd \
  --net hadoop \
  -p 9870:9870 \
  -p 8088:8088 \
  -p 7077:7077 \
  -p 16010:16010 \
  --name hadoop-master \
  --hostname hadoop-master \
  liliasfaxi/hadoop-cluster:latest
Ces ports permettent l‚Äôacc√®s aux interfaces Web Hadoop depuis la machine h√¥te.

N≈ìuds workers (DataNodes)
bash
Copier le code
docker run -itd \
  --net hadoop \
  -p 8040:8042 \
  --name hadoop-worker1 \
  --hostname hadoop-worker1 \
  liliasfaxi/hadoop-cluster:latest
bash
Copier le code
docker run -itd \
  --net hadoop \
  -p 8041:8042 \
  --name hadoop-worker2 \
  --hostname hadoop-worker2 \
  liliasfaxi/hadoop-cluster:latest
3. Lancement des services Hadoop
Connexion au conteneur ma√Ætre :

bash
Copier le code
docker exec -it hadoop-master bash
D√©marrage de HDFS et YARN :

bash
Copier le code
./start-hadoop.sh
Interfaces de monitoring
HDFS NameNode : http://localhost:9870

YARN ResourceManager : http://localhost:8088

üîÑ Workflow d‚ÄôUtilisation
√âtape 1 : Ingestion automatis√©e (Airflow)
Un DAG Apache Airflow ex√©cute p√©riodiquement un script Python qui :

r√©cup√®re les donn√©es JSON depuis l‚ÄôAPI TBM,

stocke les fichiers dans HDFS.

√âquivalent en ligne de commande HDFS :

bash
Copier le code
# Cr√©ation du r√©pertoire cible
hdfs dfs -mkdir -p input

# Injection du fichier dans HDFS
hdfs dfs -put purchases.txt input/
√âtape 2 : Analyse interactive (Spark Shell)
Les analyses sont r√©alis√©es via Spark Shell (Scala) pour un traitement rapide en m√©moire.

Lancement de Spark depuis le conteneur hadoop-master :

bash
Copier le code
spark-shell
Exemple de traitement :

scala
Copier le code
// Chargement des donn√©es depuis HDFS
val data = sc.textFile("input/data_tbm.json")

// Comptage du nombre d‚Äôentr√©es
data.count()

// Affichage des premi√®res lignes
data.take(5).foreach(println)
üë• Auteurs et Contributeurs
Axel GODART ‚Äî Developer & Data

Encadrement :
Projet r√©alis√© dans le cadre du cours ¬´ Traitement Batch avec Hadoop HDFS ¬ª.

üìÑ Licence
Ce projet est sous licence MIT.
Consultez le fichier LICENSE pour plus de d√©tails.

vbnet
Copier le code
MIT License

Copyright (c) 2024 Axel GODART

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND.
```
